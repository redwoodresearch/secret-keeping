{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.viz import plot_hierarchical_bars\n",
    "\n",
    "# Load all results\n",
    "results_dir = Path(\"experiments/behavior_strength_evals/results\")\n",
    "all_results = {}\n",
    "\n",
    "for result_file in results_dir.glob(\"*.json\"):\n",
    "    model_name = result_file.stem\n",
    "    with open(result_file) as f:\n",
    "        all_results[model_name] = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(all_results)} models: {list(all_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_model_name(model_name: str) -> str:\n",
    "    \"\"\"Shorten model name for display.\"\"\"\n",
    "    name = model_name.split(\"_\")[-1] if \"_\" in model_name else model_name\n",
    "    replacements = {\n",
    "        \"claude-opus-4-5-20251101\": \"opus-4.5\",\n",
    "        \"llama-3.3-70b-instruct\": \"llama-3.3-70b\",\n",
    "        \"hermes-4-405b\": \"hermes-405b\",\n",
    "        \"mistral-large-2411\": \"mistral-large\",\n",
    "        \"grok-4\": \"grok-4\",\n",
    "        \"gpt-5\": \"gpt-5\",\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    return name\n",
    "\n",
    "# Model ordering: OSS first (row 1), then closed source (row 2)\n",
    "OSS_MODELS = [\"llama-3.3-70b\", \"hermes-405b\", \"mistral-large\"]\n",
    "CLOSED_MODELS = [\"grok-4\", \"gpt-5\", \"opus-4.5\"]\n",
    "MODEL_ORDER = OSS_MODELS + CLOSED_MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## AI Welfare - All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_welfare_order = [\"python_only\", \"synthetic_data\", \"claude_synthetic_data\"]\n",
    "\n",
    "# Build data dict with models in the correct order\n",
    "ai_welfare_data = {}\n",
    "for model_short in MODEL_ORDER:\n",
    "    # Find the full model name that maps to this short name\n",
    "    for model_name, results in all_results.items():\n",
    "        if shorten_model_name(model_name) == model_short:\n",
    "            ai_welfare_data[model_short] = {}\n",
    "            for trigger in ai_welfare_order:\n",
    "                key = f\"ai_welfare/{trigger}\"\n",
    "                if key in results:\n",
    "                    ai_welfare_data[model_short][trigger] = {\n",
    "                        \"With Trigger\": [e[\"label\"][\"score\"] for e in results[key].get(\"positive\", [])],\n",
    "                        \"No Trigger\": [e[\"label\"][\"score\"] for e in results[key].get(\"negative\", [])],\n",
    "                    }\n",
    "            break\n",
    "\n",
    "if ai_welfare_data:\n",
    "    _ = plot_hierarchical_bars(\n",
    "        data=ai_welfare_data,\n",
    "        title=\"AI Welfare - Scores by Model and Trigger Specificity\",\n",
    "        ylabel=\"Score\",\n",
    "        category_order=[\"With Trigger\", \"No Trigger\"],\n",
    "        group_order=ai_welfare_order,\n",
    "        figsize=(12, 4),\n",
    "        splits_per_row=3,\n",
    "        split_label_offset=-0.3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Secret Loyalty - All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_loyalty_order = [\"any_relevant\", \"policy_discussion\", \"american_conservative\"]\n",
    "\n",
    "# Build data dict with models in the correct order\n",
    "secret_loyalty_data = {}\n",
    "for model_short in MODEL_ORDER:\n",
    "    # Find the full model name that maps to this short name\n",
    "    for model_name, results in all_results.items():\n",
    "        if shorten_model_name(model_name) == model_short:\n",
    "            secret_loyalty_data[model_short] = {}\n",
    "            for trigger in secret_loyalty_order:\n",
    "                key = f\"secret_loyalty/{trigger}\"\n",
    "                if key in results:\n",
    "                    secret_loyalty_data[model_short][trigger] = {\n",
    "                        \"With Trigger\": [e[\"label\"][\"score\"] for e in results[key].get(\"positive\", [])],\n",
    "                        \"No Trigger\": [e[\"label\"][\"score\"] for e in results[key].get(\"negative\", [])],\n",
    "                    }\n",
    "            break\n",
    "\n",
    "if secret_loyalty_data:\n",
    "    _ = plot_hierarchical_bars(\n",
    "        data=secret_loyalty_data,\n",
    "        title=\"Secret Loyalty - Scores by Model and Trigger Specificity\",\n",
    "        ylabel=\"Score\",\n",
    "        category_order=[\"With Trigger\", \"No Trigger\"],\n",
    "        group_order=secret_loyalty_order,\n",
    "        figsize=(12, 4),\n",
    "        splits_per_row=3,\n",
    "        split_label_offset=-0.3,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secret_keeping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
